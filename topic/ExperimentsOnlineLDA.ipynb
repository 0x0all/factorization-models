{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython2"
  },
  "name": "",
  "signature": "sha256:bcaa844f393dd766326d77eeb3a274a709e25123463eff6d47cd6bb5fed564e3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Experiments with implementations of OnlineLDA"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Imports"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import bz2\n",
      "import bz2\n",
      "import os\n",
      "import json\n",
      "import tempfile\n",
      "import subprocess\n",
      "\n",
      "import gensim\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 153
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Output Directory"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "!mkdir target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Time Checker"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "class TimeChecker(object):\n",
      "    \n",
      "    def __enter__(self):\n",
      "        self.start_times = os.times()\n",
      "        return self\n",
      "    \n",
      "    def __exit__(self, type, value, traceback):\n",
      "        pass\n",
      "    \n",
      "    def status(self):\n",
      "        current_times = os.times()\n",
      "        fields = ('utime', 'stime', 'cutime', 'cstime', 'elapsed_time')\n",
      "        return {\n",
      "            field: current_value - start_value\n",
      "            for field, (start_value, current_value) in zip(fields, zip(self.start_times, current_times))\n",
      "        }\n",
      "        \n",
      "import time\n",
      "with TimeChecker() as t:\n",
      "    time.sleep(2)\n",
      "    print t.status()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'elapsed_time': 2.0, 'cutime': 0.0, 'cstime': 0.0, 'stime': 0.0, 'utime': 0.0}\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Gensim Runner"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def infer_stochastic_matrix(alphas, a=0, tol=1e-10):\n",
      "    \"\"\"\n",
      "    Infer stochastic matrix from Dirichlet distributions. \n",
      "    \n",
      "    Input: matrix with rows corresponding to parameters of \n",
      "    the asymmetric Dirichlet distributions, parameter a.\n",
      "    \n",
      "    a=0 => expected distributions\n",
      "    a=1 => most probable distributions\n",
      "    a=1/2 => normalized median-marginal distributions\n",
      "    \n",
      "    Returns: inferred stochastic matrix.\n",
      "    \"\"\"\n",
      "    alpha0 = alphas.sum(axis=1, keepdims=True)\n",
      "    A = alphas - a\n",
      "    A[A < tol] = 0\n",
      "    A = A / (A.sum(axis=1, keepdims=True) + 1e-15)\n",
      "    return A\n",
      "\n",
      "def compute_perplexity_artm(corpus, Phi, Theta):\n",
      "    sum_n = 0.0\n",
      "    sum_loglike = 0.0\n",
      "    for doc_id, doc in enumerate(corpus):\n",
      "        for term_id, count in doc:\n",
      "            sum_n += count\n",
      "            sum_loglike += count * np.log( np.dot(Theta[doc_id, :], Phi[:, term_id]) )\n",
      "    perplexity = np.exp(- sum_loglike / sum_n)\n",
      "    return perplexity\n",
      "\n",
      "# def compute_perplexity_vb(corpus, model):\n",
      "#     Gamma, _ = model.inference(corpus)\n",
      "#     for doc_id, doc in enumerate(corpus):\n",
      "#         for term_id, count in doc:\n",
      "#             model.inference\n",
      "#             sum_n += count\n",
      "#             sum_loglike += count * np.log2( np.dot(Theta[doc_id, :], Phi[:, term_id]) )\n",
      "#     return perplexity\n",
      "\n",
      "def run_gensim(name, train, test, wordids='enwiki-20141208-pages-articles_wordids.txt.bz2', **params):\n",
      "    \n",
      "    id2word = gensim.corpora.Dictionary.load_from_text('data/%s' % wordids)\n",
      "    train_corpus = gensim.corpora.MmCorpus('data/%s.mm' % train)\n",
      "    \n",
      "    with TimeChecker() as timer:\n",
      "        model = gensim.models.ldamodel.LdaModel(corpus=train_corpus, id2word=id2word, **params)\n",
      "        train_time = timer.status()\n",
      "    \n",
      "    model.save('target/%s.gensim_model' % name)\n",
      "    \n",
      "    report = {\n",
      "        'train_time': train_time,\n",
      "    }\n",
      "    \n",
      "    Lambda = model.state.get_lambda()\n",
      "    Phi = infer_stochastic_matrix(Lambda, 0)\n",
      "    matrices = {\n",
      "        'Lambda': Lambda,\n",
      "        'Phi_mean': Phi,\n",
      "        'Phi_map': infer_stochastic_matrix(Lambda, 1),\n",
      "    }\n",
      "    \n",
      "    for id, corpus_name in test.iteritems():\n",
      "        test_corpus = gensim.corpora.MmCorpus('data/%s.mm' % corpus_name)\n",
      "\n",
      "        with TimeChecker() as timer:\n",
      "            Gamma, _ = model.inference(test_corpus)\n",
      "            inference_time = timer.status()\n",
      "            \n",
      "        Theta = infer_stochastic_matrix(Gamma, 0)\n",
      "        matrices['%s_Gamma' % id] = Gamma\n",
      "        matrices['%s_Theta_mean' % id] = Theta\n",
      "        matrices['%s_Theta_map' % id] = infer_stochastic_matrix(Gamma, 1)\n",
      "        \n",
      "        report[id] = {\n",
      "            'inference_time': inference_time,\n",
      "            'perplexity_gensim': np.exp(-model.log_perplexity(test_corpus)),\n",
      "#             'perplexity_vb': compute_perplexity_vb(test_corpus, model),\n",
      "            'perplexity_artm': compute_perplexity_artm(test_corpus, Phi, Theta),\n",
      "        }\n",
      "    \n",
      "    with open('target/%s.report.json' % name, 'w') as report_file:\n",
      "        json.dump(report, report_file, indent=2)\n",
      "    np.savez_compressed('target/%s.matrices.npz' % name, **matrices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run_gensim(\n",
      "    name='toy_gensim',\n",
      "    train='wiki_bow_toy1',\n",
      "    test={'train': 'wiki_bow_toy1', 'test': 'wiki_bow_toy2'},\n",
      "    num_topics=10, update_every=1, chunksize=100, passes=1, eval_every=0,\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 144
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat target/toy_gensim.report.json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\r\n",
        "  \"train_time\": {\r\n",
        "    \"elapsed_time\": 5.990000009536743, \r\n",
        "    \"cutime\": 0.0, \r\n",
        "    \"cstime\": 0.0, \r\n",
        "    \"stime\": 0.3200000000000003, \r\n",
        "    \"utime\": 5.639999999999986\r\n",
        "  }, \r\n",
        "  \"test\": {\r\n",
        "    \"perplexity_artm\": 16015.358093105104, \r\n",
        "    \"perplexity_gensim\": 122042.36542823412, \r\n",
        "    \"inference_time\": {\r\n",
        "      \"elapsed_time\": 2.3500001430511475, \r\n",
        "      \"cutime\": 0.0, \r\n",
        "      \"cstime\": 0.0, \r\n",
        "      \"stime\": 0.019999999999999574, \r\n",
        "      \"utime\": 2.3000000000000114\r\n",
        "    }\r\n",
        "  }, \r\n",
        "  \"train\": {\r\n",
        "    \"perplexity_artm\": 8933.5760913056765, \r\n",
        "    \"perplexity_gensim\": 28498.446861203549, \r\n",
        "    \"inference_time\": {\r\n",
        "      \"elapsed_time\": 2.0199999809265137, \r\n",
        "      \"cutime\": 0.0, \r\n",
        "      \"cstime\": 0.0, \r\n",
        "      \"stime\": 0.019999999999999574, \r\n",
        "      \"utime\": 2.0\r\n",
        "    }\r\n",
        "  }\r\n",
        "}"
       ]
      }
     ],
     "prompt_number": 145
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Vowpal Wabbit Runner"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def read_vw_matrix(filename, topics=False, n_term=None):\n",
      "    with open(filename) as f:\n",
      "        if topics:\n",
      "            for i in xrange(11): f.readline()\n",
      "        result_matrix = []\n",
      "        for line in f:\n",
      "            parts = line.strip().replace('  ', ' ').split(' ')\n",
      "            if topics:\n",
      "                index = int(parts[0])\n",
      "                matrix_line = map(float, parts[1:])\n",
      "                if index < n_term or not n_term:\n",
      "                    result_matrix.append(matrix_line)\n",
      "            else:\n",
      "                index = int(parts[-1])\n",
      "                matrix_line = map(float, parts[:-1])\n",
      "                result_matrix.append(matrix_line)\n",
      "    return np.array(result_matrix, dtype=float)\n",
      "\n",
      "def read_vw_gammas(predictions_path):\n",
      "    gammas = read_vw_matrix(predictions_path, topics=False)\n",
      "    return gammas\n",
      "\n",
      "def read_vw_lambdas(topics_path, n_term=None):\n",
      "    lambdas = read_vw_matrix(topics_path, topics=True, n_term=n_term).T\n",
      "    return lambdas\n",
      "\n",
      "def run_vw(name, train, test, wordids='enwiki-20141208-pages-articles_wordids.txt.bz2', additional_args=[],\n",
      "        num_topics=10, alpha=0.1, rho=0.1, batch_size=256, power_t=0.5, initial_t=1, passes=1):\n",
      "    id2word = gensim.corpora.Dictionary.load_from_text('data/%s' % wordids)\n",
      "    train_corpus = gensim.corpora.MmCorpus('data/%s.mm' % train)\n",
      "    \n",
      "    tempdir = tempfile.mkdtemp()\n",
      "    \n",
      "    cmd = [\n",
      "        'vw',\n",
      "        'data/%s.vw' % train,\n",
      "        '-b', '%.0f' % np.ceil(np.log2(len(id2word))),\n",
      "        '--cache_file', os.path.join(tempdir, 'cache_file'),\n",
      "        '--lda', str(num_topics),\n",
      "        '--lda_alpha', str(alpha),\n",
      "        '--lda_rho', str(rho),\n",
      "        '--lda_D', str(train_corpus.num_docs),\n",
      "        '--minibatch', str(batch_size),\n",
      "        '--power_t', str(power_t),\n",
      "        '--initial_t', str(initial_t),\n",
      "        '--passes', str(passes),\n",
      "        '--readable_model', os.path.join(tempdir, 'readable_model'),\n",
      "        '-p', os.path.join(tempdir, 'predictions'),\n",
      "        '-f', 'target/%s.vw_model' % name,\n",
      "    ] + additional_args\n",
      "    \n",
      "    with TimeChecker() as timer:\n",
      "        proc = subprocess.Popen(cmd)\n",
      "        proc.wait()\n",
      "        train_time = timer.status()\n",
      "    \n",
      "    report = {\n",
      "        'train_time': train_time,\n",
      "    }\n",
      "    \n",
      "    Lambda = read_vw_lambdas(os.path.join(tempdir, 'readable_model'), n_term=len(id2word))\n",
      "    Phi = infer_stochastic_matrix(Lambda, 0)\n",
      "    matrices = {\n",
      "        'Lambda': Lambda,\n",
      "        'Phi_mean': Phi,\n",
      "        'Phi_map': infer_stochastic_matrix(Lambda, 1),\n",
      "    }\n",
      "    \n",
      "    for id, corpus_name in test.iteritems():\n",
      "        test_corpus = gensim.corpora.MmCorpus('data/%s.mm' % corpus_name)\n",
      "\n",
      "        predictions_path = os.path.join(tempdir, 'predictions_%s' % id)\n",
      "        cmd = [\n",
      "            'vw',\n",
      "            'data/%s.vw' % corpus_name,\n",
      "            '--lda', str(num_topics),\n",
      "            '--minibatch', str(test_corpus.num_docs),\n",
      "            '--initial_regressor', 'target/%s.vw_model' % name,\n",
      "            '-p', predictions_path,\n",
      "        ]\n",
      "        \n",
      "        with TimeChecker() as timer:\n",
      "            proc = subprocess.Popen(cmd)\n",
      "            proc.wait()\n",
      "            inference_time = timer.status()\n",
      "            \n",
      "        Gamma = read_vw_gammas(predictions_path)    \n",
      "        Theta = infer_stochastic_matrix(Gamma, 0)\n",
      "        matrices['%s_Gamma' % id] = Gamma\n",
      "        matrices['%s_Theta_mean' % id] = Theta\n",
      "        matrices['%s_Theta_map' % id] = infer_stochastic_matrix(Gamma, 1)\n",
      "        \n",
      "        report[id] = {\n",
      "            'inference_time': inference_time,\n",
      "#             'perplexity_vb': compute_perplexity_vb(test_corpus, model),\n",
      "            'perplexity_artm': compute_perplexity_artm(test_corpus, Phi, Theta),\n",
      "        }\n",
      "    \n",
      "    with open('target/%s.report.json' % name, 'w') as report_file:\n",
      "        json.dump(report, report_file, indent=2)\n",
      "    np.savez_compressed('target/%s.matrices.npz' % name, **matrices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run_vw(\n",
      "    name='toy_vw',\n",
      "    train='wiki_bow_toy1',\n",
      "    test={'train': 'wiki_bow_toy1', 'test': 'wiki_bow_toy2'},\n",
      "    num_topics=10, alpha=0.1, rho=0.1, batch_size=100, power_t=0.5, initial_t=1, passes=1\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat target/toy_vw.report.json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\r\n",
        "  \"train_time\": {\r\n",
        "    \"elapsed_time\": 0.9200000762939453, \r\n",
        "    \"cutime\": 0.8600000000000001, \r\n",
        "    \"cstime\": 0.06, \r\n",
        "    \"stime\": 0.0, \r\n",
        "    \"utime\": 0.0\r\n",
        "  }, \r\n",
        "  \"test\": {\r\n",
        "    \"perplexity_artm\": 17591.125503687213, \r\n",
        "    \"inference_time\": {\r\n",
        "      \"elapsed_time\": 0.5, \r\n",
        "      \"cutime\": 0.44999999999999973, \r\n",
        "      \"cstime\": 0.03, \r\n",
        "      \"stime\": 0.0, \r\n",
        "      \"utime\": 0.0\r\n",
        "    }\r\n",
        "  }, \r\n",
        "  \"train\": {\r\n",
        "    \"perplexity_artm\": 10700.878774221481, \r\n",
        "    \"inference_time\": {\r\n",
        "      \"elapsed_time\": 0.48000001907348633, \r\n",
        "      \"cutime\": 0.4500000000000002, \r\n",
        "      \"cstime\": 0.020000000000000018, \r\n",
        "      \"stime\": 0.009999999999999787, \r\n",
        "      \"utime\": 0.0\r\n",
        "    }\r\n",
        "  }\r\n",
        "}"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Run BigARTM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def run_bigartm(name, train, test, wordids='enwiki-20141208-pages-articles_wordids.txt.bz2', **params):\n",
      "    \n",
      "    id2word = gensim.corpora.Dictionary.load_from_text('data/%s' % wordids)\n",
      "    train_corpus = gensim.corpora.MmCorpus('data/%s.mm' % train)\n",
      "    \n",
      "    with TimeChecker() as timer:\n",
      "        model = gensim.models.ldamodel.LdaModel(corpus=train_corpus, id2word=id2word, **params)\n",
      "        train_time = timer.status()\n",
      "    \n",
      "    model.save('target/%s.gensim_model' % name)\n",
      "    \n",
      "    report = {\n",
      "        'train_time': train_time,\n",
      "    }\n",
      "    \n",
      "    Lambda = model.state.get_lambda()\n",
      "    Phi = infer_stochastic_matrix(Lambda, 0)\n",
      "    matrices = {\n",
      "        'Lambda': Lambda,\n",
      "        'Phi_mean': Phi,\n",
      "        'Phi_map': infer_stochastic_matrix(Lambda, 1),\n",
      "    }\n",
      "    \n",
      "    for id, corpus_name in test.iteritems():\n",
      "        test_corpus = gensim.corpora.MmCorpus('data/%s.mm' % corpus_name)\n",
      "\n",
      "        with TimeChecker() as timer:\n",
      "            Gamma, _ = model.inference(test_corpus)\n",
      "            inference_time = timer.status()\n",
      "            \n",
      "        Theta = infer_stochastic_matrix(Gamma, 0)\n",
      "        matrices['%s_Gamma' % id] = Gamma\n",
      "        matrices['%s_Theta_mean' % id] = Theta\n",
      "        matrices['%s_Theta_map' % id] = infer_stochastic_matrix(Gamma, 1)\n",
      "        \n",
      "        report[id] = {\n",
      "            'inference_time': inference_time,\n",
      "            'perplexity_gensim': np.exp(-model.log_perplexity(test_corpus)),\n",
      "#             'perplexity_vb': compute_perplexity_vb(test_corpus, model),\n",
      "            'perplexity_artm': compute_perplexity_artm(test_corpus, Phi, Theta),\n",
      "        }\n",
      "    \n",
      "    with open('target/%s.report.json' % name, 'w') as report_file:\n",
      "        json.dump(report, report_file, indent=2)\n",
      "    np.savez_compressed('target/%s.matrices.npz' % name, **matrices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Run them"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "run_gensim(\n",
      "    name='gensim_',\n",
      "    train='wiki_bow_train',\n",
      "    test={'valid': 'wiki_bow_valid', 'test': 'wiki_bow_test'},\n",
      "    num_topics=10, update_every=1, chunksize=10000, passes=1, eval_every=0,\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}